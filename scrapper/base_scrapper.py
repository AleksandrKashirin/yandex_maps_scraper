"""
–û—Å–Ω–æ–≤–Ω–æ–π –∫–ª–∞—Å—Å –¥–ª—è —Å–∫—Ä–∞–ø–∏–Ω–≥–∞ –¥–∞–Ω–Ω—ã—Ö —Å –Ø–Ω–¥–µ–∫—Å.–ö–∞—Ä—Ç
"""

import json
import re
import time
from datetime import datetime
from typing import Any, Dict, List, Optional, Union
from urllib.parse import urlparse

from pydantic import BaseModel, Field, ValidationError
from selenium import webdriver
from selenium.common.exceptions import TimeoutException, WebDriverException
from tenacity import retry, stop_after_attempt, wait_exponential

from config.chrome_config import ChromeConfig, user_agent_rotator
from config.settings import settings
from core.logger import get_logger, log_scraping_stats, scraping_metrics

from .navigation import NavigationError, YandexMapsNavigator
from .selectors import selectors


class ServiceData(BaseModel):
    """–ú–æ–¥–µ–ª—å –¥–∞–Ω–Ω—ã—Ö —É—Å–ª—É–≥–∏"""

    name: str
    price: Optional[str] = None
    price_from: Optional[str] = None
    price_to: Optional[str] = None
    description: Optional[str] = None
    duration: Optional[str] = None


class SocialNetworks(BaseModel):
    """–ú–æ–¥–µ–ª—å —Å–æ—Ü–∏–∞–ª—å–Ω—ã—Ö —Å–µ—Ç–µ–π"""

    telegram: Optional[str] = None
    whatsapp: Optional[str] = None
    vk: Optional[str] = None


class WorkingHours(BaseModel):
    """–ú–æ–¥–µ–ª—å —Ä–∞–±–æ—á–∏—Ö —á–∞—Å–æ–≤"""

    current_status: Optional[str] = None
    schedule: Optional[Dict[str, str]] = None
    notes: Optional[str] = None


class ReviewData(BaseModel):
    """–ú–æ–¥–µ–ª—å –æ—Ç–∑—ã–≤–∞"""

    author: str
    rating: Optional[int] = None
    date: Optional[str] = None
    text: Optional[str] = None
    response: Optional[str] = None


class BusinessData(BaseModel):
    """–ú–æ–¥–µ–ª—å –¥–∞–Ω–Ω—ã—Ö –ø—Ä–µ–¥–ø—Ä–∏—è—Ç–∏—è"""

    name: str
    category: Optional[str] = None
    services: List[ServiceData] = Field(default_factory=list)
    website: Optional[str] = None
    address: Optional[str] = None
    social_networks: SocialNetworks = Field(default_factory=SocialNetworks)
    phone: Optional[str] = None
    working_hours: WorkingHours = Field(default_factory=WorkingHours)
    rating: Optional[float] = None
    reviews_count: Optional[int] = None
    reviews: List[ReviewData] = Field(default_factory=list)
    scraping_date: datetime = Field(default_factory=datetime.now)
    metadata: Dict[str, Any] = Field(default_factory=dict)


class YandexMapsScraper:
    """–û—Å–Ω–æ–≤–Ω–æ–π –∫–ª–∞—Å—Å –¥–ª—è —Å–∫—Ä–∞–ø–∏–Ω–≥–∞ –Ø–Ω–¥–µ–∫—Å.–ö–∞—Ä—Ç"""

    def __init__(self, config: Optional[Dict] = None):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–∫—Ä–∞–ø–µ—Ä–∞

        Args:
            config: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
        """
        self.config = config or {}
        self.logger = get_logger(__name__)
        self.driver: Optional[webdriver.Chrome] = None
        self.navigator: Optional[YandexMapsNavigator] = None
        self.start_time: Optional[float] = None

    def __enter__(self):
        """–ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä - –≤—Ö–æ–¥"""
        self.initialize_driver()
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        """–ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä - –≤—ã—Ö–æ–¥"""
        self.cleanup()

    def initialize_driver(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è WebDriver"""
        try:
            self.logger.info("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Chrome WebDriver")

            # –ü–æ–ª—É—á–∞–µ–º –Ω–æ–≤—ã–π User-Agent
            user_agent = None
            if settings.ROTATE_USER_AGENT:
                user_agent = user_agent_rotator.get_best_user_agent()
                self.logger.debug(f"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è User-Agent: {user_agent[:50]}...")

            # –°–æ–∑–¥–∞–µ–º –¥—Ä–∞–π–≤–µ—Ä
            self.driver = ChromeConfig.create_driver(user_agent)
            self.navigator = YandexMapsNavigator(self.driver)

            self.logger.info("WebDriver —É—Å–ø–µ—à–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")

        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ WebDriver: {e}")
            raise

    def cleanup(self):
        """–û—á–∏—Å—Ç–∫–∞ —Ä–µ—Å—É—Ä—Å–æ–≤"""
        if self.driver:
            try:
                self.driver.quit()
                self.logger.info("WebDriver –∑–∞–∫—Ä—ã—Ç")
            except Exception as e:
                self.logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–∫—Ä—ã—Ç–∏–∏ WebDriver: {e}")

    def validate_url(self, url: str) -> bool:
        """
        –í–∞–ª–∏–¥–∞—Ü–∏—è URL –Ø–Ω–¥–µ–∫—Å.–ö–∞—Ä—Ç

        Args:
            url: URL –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏

        Returns:
            bool: True –µ—Å–ª–∏ URL –≤–∞–ª–∏–¥–µ–Ω
        """
        try:
            parsed = urlparse(url)

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ö–µ–º—É
            if parsed.scheme not in ["http", "https"]:
                return False

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ–º–µ–Ω
            domain_valid = any(
                domain in parsed.netloc for domain in settings.YANDEX_MAPS_DOMAINS
            )

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—É—Ç—å
            path_valid = "/maps/" in parsed.path

            return domain_valid and path_valid

        except Exception:
            return False

    @retry(
        stop=stop_after_attempt(3), wait=wait_exponential(multiplier=2, min=4, max=10)
    )
    def load_page(self, url: str) -> bool:
        """
        –ó–∞–≥—Ä—É–∑–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Å –ø–æ–≤—Ç–æ—Ä–Ω—ã–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏

        Args:
            url: URL —Å—Ç—Ä–∞–Ω–∏—Ü—ã

        Returns:
            bool: True –µ—Å–ª–∏ —Å—Ç—Ä–∞–Ω–∏—Ü–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ
        """
        if not self.validate_url(url):
            raise ValueError(f"–ù–µ–≤–∞–ª–∏–¥–Ω—ã–π URL: {url}")

        self.logger.info(f"–ó–∞–≥—Ä—É–∑–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã: {url}")
        self.start_time = time.time()

        try:
            self.driver.get(url)

            # –ñ–¥–µ–º –∑–∞–≥—Ä—É–∑–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
            if not self.navigator.wait_for_page_load():
                raise TimeoutException("–°—Ç—Ä–∞–Ω–∏—Ü–∞ –Ω–µ –∑–∞–≥—Ä—É–∑–∏–ª–∞—Å—å –≤ –æ—Ç–≤–µ–¥–µ–Ω–Ω–æ–µ –≤—Ä–µ–º—è")

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –∫–∞–ø—á—É
            if self.navigator.check_for_captcha():
                raise NavigationError("–û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –∫–∞–ø—á–∞")

            # –ò–º–∏—Ç–∏—Ä—É–µ–º –ø–æ–≤–µ–¥–µ–Ω–∏–µ —á–µ–ª–æ–≤–µ–∫–∞
            self.navigator.simulate_human_behavior()

            self.logger.info("–°—Ç—Ä–∞–Ω–∏—Ü–∞ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")

            return True

        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã: {e}")
            raise

    def extract_basic_info(self) -> Dict[str, Any]:
        """
        –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –±–∞–∑–æ–≤–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –ø—Ä–µ–¥–ø—Ä–∏—è—Ç–∏–∏

        Returns:
            Dict: –°–ª–æ–≤–∞—Ä—å —Å –±–∞–∑–æ–≤–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
        """
        self.logger.info("–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –±–∞–∑–æ–≤–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏")

        data = {}

        # –ù–∞–∑–≤–∞–Ω–∏–µ
        name_element = self.navigator.find_element_with_fallback(
            selectors.BASIC_INFO["name"]
        )
        if name_element:
            data["name"] = name_element.text.strip()
            self.logger.debug(f"–ù–∞–∑–≤–∞–Ω–∏–µ: {data['name']}")

        # –ö–∞—Ç–µ–≥–æ—Ä–∏—è
        category_element = self.navigator.find_element_with_fallback(
            selectors.BASIC_INFO["category"]
        )
        if category_element:
            data["category"] = category_element.text.strip()
            self.logger.debug(f"–ö–∞—Ç–µ–≥–æ—Ä–∏—è: {data['category']}")

        # –†–µ–π—Ç–∏–Ω–≥
        rating_element = self.navigator.find_element_with_fallback(
            selectors.BASIC_INFO["rating"]
        )
        if rating_element:
            rating_text = rating_element.text.strip()
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —á–∏—Å–ª–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ —Ä–µ–π—Ç–∏–Ω–≥–∞
            rating_match = re.search(r"(\d+[\.,]\d+)", rating_text)
            if rating_match:
                data["rating"] = float(rating_match.group(1).replace(",", "."))
                self.logger.debug(f"–†–µ–π—Ç–∏–Ω–≥: {data['rating']}")

        # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ç–∑—ã–≤–æ–≤
        reviews_count_element = self.navigator.find_element_with_fallback(
            selectors.BASIC_INFO["reviews_count"]
        )
        if reviews_count_element:
            reviews_text = reviews_count_element.text.strip()
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —á–∏—Å–ª–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
            reviews_match = re.search(r"(\d+)", reviews_text)
            if reviews_match:
                data["reviews_count"] = int(reviews_match.group(1))
                self.logger.debug(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ç–∑—ã–≤–æ–≤: {data['reviews_count']}")

        # –ê–¥—Ä–µ—Å
        address_element = self.navigator.find_element_with_fallback(
            selectors.BASIC_INFO["address"]
        )
        if address_element:
            data["address"] = address_element.text.strip()
            self.logger.debug(f"–ê–¥—Ä–µ—Å: {data['address']}")

        # –¢–µ–ª–µ—Ñ–æ–Ω
        phone_elements = self.navigator.find_element_with_fallback(
            selectors.BASIC_INFO["phone"]
        )
        if phone_elements:
            if isinstance(phone_elements, list):
                # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π —Ç–µ–ª–µ—Ñ–æ–Ω
                data["phone"] = phone_elements[0].text.strip()
            else:
                data["phone"] = phone_elements.text.strip()
            self.logger.debug(f"–¢–µ–ª–µ—Ñ–æ–Ω: {data['phone']}")

        # –°–∞–π—Ç
        website_element = self.navigator.find_element_with_fallback(
            selectors.BASIC_INFO["website"]
        )
        if website_element:
            href = website_element.get_attribute("href")
            if href:
                data["website"] = href
                self.logger.debug(f"–°–∞–π—Ç: {data['website']}")

        # –ß–∞—Å—ã —Ä–∞–±–æ—Ç—ã
        working_hours_element = self.navigator.find_element_with_fallback(
            selectors.BASIC_INFO["working_hours"]
        )
        if working_hours_element:
            data["working_hours"] = {
                "current_status": working_hours_element.text.strip()
            }
            self.logger.debug(
                f"–°—Ç–∞—Ç—É—Å —Ä–∞–±–æ—Ç—ã: {data['working_hours']['current_status']}"
            )

        return data

    def extract_social_networks(self) -> Dict[str, str]:
        """
        –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å—Å—ã–ª–æ–∫ –Ω–∞ —Å–æ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–µ—Ç–∏

        Returns:
            Dict: –°–ª–æ–≤–∞—Ä—å —Å —Å–æ—Ü–∏–∞–ª—å–Ω—ã–º–∏ —Å–µ—Ç—è–º–∏
        """
        self.logger.debug("–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å–æ—Ü–∏–∞–ª—å–Ω—ã—Ö —Å–µ—Ç–µ–π")

        social_data = {}

        for network, config in selectors.SOCIAL_NETWORKS.items():
            element = self.navigator.find_element_with_fallback(config)
            if element:
                href = element.get_attribute("href")
                if href:
                    social_data[network] = href
                    self.logger.debug(f"{network}: {href}")

        return social_data

    def navigate_to_services_tab(self) -> bool:
        """
        –ü–µ—Ä–µ—Ö–æ–¥ –Ω–∞ –≤–∫–ª–∞–¥–∫—É —É—Å–ª—É–≥

        Returns:
            bool: True –µ—Å–ª–∏ –ø–µ—Ä–µ—Ö–æ–¥ —É—Å–ø–µ—à–µ–Ω
        """
        return self.navigator.navigate_to_services_tab()

    def extract_services(self) -> List[Dict[str, Any]]:
        """
        –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —É—Å–ª—É–≥ –∏ —Ü–µ–Ω

        Returns:
            List: –°–ø–∏—Å–æ–∫ —É—Å–ª—É–≥
        """
        self.logger.info("–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —É—Å–ª—É–≥")
        services = []

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —É—Å–ª—É–≥–∏ –µ—Å–ª–∏ –µ—Å—Ç—å
        self.navigator.load_more_content("services")

        # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ —ç–ª–µ–º–µ–Ω—Ç—ã —É—Å–ª—É–≥
        service_elements = self.navigator.find_element_with_fallback(
            selectors.SERVICES["service_items"]
        )

        if not service_elements:
            self.logger.warning("–£—Å–ª—É–≥–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
            return services

        if not isinstance(service_elements, list):
            service_elements = [service_elements]

        total_elements = len(service_elements)
        self.logger.info(f"–ù–∞–π–¥–µ–Ω–æ {total_elements} —ç–ª–µ–º–µ–Ω—Ç–æ–≤ —É—Å–ª—É–≥")

        # Progress bar setup
        progress_step = max(1, total_elements // 10)  # –û–±–Ω–æ–≤–ª—è–µ–º –∫–∞–∂–¥—ã–µ 10%

        for i, element in enumerate(service_elements, 1):
            try:
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
                if i % progress_step == 0 or i == total_elements:
                    percentage = (i / total_elements) * 100
                    filled = int(percentage // 5)  # 20 —Å–∏–º–≤–æ–ª–æ–≤ = 100%
                    bar = "‚ñà" * filled + "‚ñë" * (20 - filled)
                    print(
                        f"\rüîç –û–±—Ä–∞–±–æ—Ç–∫–∞ —É—Å–ª—É–≥: [{bar}] {percentage:.0f}% ({i}/{total_elements}) | –ù–∞–π–¥–µ–Ω–æ: {len(services)}",
                        end="",
                        flush=True,
                    )

                service_data = {}

                # –ë–´–°–¢–†–ê–Ø –ü–†–û–í–ï–†–ö–ê: –µ—Å—Ç—å –ª–∏ –Ω–∞–∑–≤–∞–Ω–∏–µ —É—Å–ª—É–≥–∏ –≤–æ–æ–±—â–µ
                name_element = self.navigator.find_element_with_fallback(
                    selectors.SERVICES["service_name"], element
                )
                if not name_element:
                    continue  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —ç–ª–µ–º–µ–Ω—Ç—ã –±–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è

                service_data["name"] = name_element.text.strip()
                if not service_data["name"]:
                    continue  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—É—Å—Ç—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è

                # –¶–µ–Ω–∞
                price_element = self.navigator.find_element_with_fallback(
                    selectors.SERVICES["service_price"], element
                )
                if price_element:
                    price_text = price_element.text.strip()
                    service_data.update(self._parse_price(price_text))

                # –û–ø–∏—Å–∞–Ω–∏–µ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
                try:
                    desc_element = self.navigator.find_element_with_fallback(
                        selectors.SERVICES["service_description"], element
                    )
                    if desc_element:
                        desc_text = desc_element.text.strip()
                        if desc_text:
                            service_data["description"] = desc_text
                except:
                    pass

                services.append(service_data)
                self.logger.debug(
                    f"–£—Å–ª—É–≥–∞ #{len(services)}: {service_data.get('name')} - {service_data.get('price', '–¶–µ–Ω–∞ –Ω–µ —É–∫–∞–∑–∞–Ω–∞')}"
                )

            except Exception as e:
                self.logger.debug(f"–ü—Ä–æ–ø—É—Å–∫–∞–µ–º —ç–ª–µ–º–µ–Ω—Ç #{i}: {e}")
                continue

        # –ó–∞–≤–µ—Ä—à–∞–µ–º progress bar
        print()  # –ù–æ–≤–∞—è —Å—Ç—Ä–æ–∫–∞ –ø–æ—Å–ª–µ progress bar
        self.logger.info(f"–ò–∑–≤–ª–µ—á–µ–Ω–æ {len(services)} —É—Å–ª—É–≥")
        return services

    def navigate_to_reviews_tab(self) -> bool:
        """
        –ü–µ—Ä–µ—Ö–æ–¥ –Ω–∞ –≤–∫–ª–∞–¥–∫—É –æ—Ç–∑—ã–≤–æ–≤

        Returns:
            bool: True –µ—Å–ª–∏ –ø–µ—Ä–µ—Ö–æ–¥ —É—Å–ø–µ—à–µ–Ω
        """
        return self.navigator.navigate_to_reviews_tab()

    def extract_reviews(self, max_reviews: int = 50) -> List[Dict[str, Any]]:
        """
        –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –æ—Ç–∑—ã–≤–æ–≤

        Args:
            max_reviews: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ç–∑—ã–≤–æ–≤ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è

        Returns:
            List: –°–ø–∏—Å–æ–∫ –æ—Ç–∑—ã–≤–æ–≤
        """
        self.logger.info(f"–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –æ—Ç–∑—ã–≤–æ–≤ (–º–∞–∫—Å. {max_reviews})")

        reviews = []

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –æ—Ç–∑—ã–≤—ã
        self.navigator.load_more_content("reviews")

        # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ –æ—Ç–∑—ã–≤—ã
        review_elements = self.navigator.find_element_with_fallback(
            selectors.REVIEWS["review_items"]
        )

        if not review_elements:
            self.logger.warning("–û—Ç–∑—ã–≤—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
            return reviews

        if not isinstance(review_elements, list):
            review_elements = [review_elements]

        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ç–∑—ã–≤–æ–≤
        review_elements = review_elements[:max_reviews]

        for element in review_elements:
            try:
                review_data = {}

                # –ê–≤—Ç–æ—Ä
                author_element = self.navigator.find_element_with_fallback(
                    selectors.REVIEWS["review_author"], element
                )
                if author_element:
                    review_data["author"] = author_element.text.strip()

                # –†–µ–π—Ç–∏–Ω–≥
                rating_element = self.navigator.find_element_with_fallback(
                    selectors.REVIEWS["review_rating"], element
                )
                if rating_element:
                    aria_label = rating_element.get_attribute("aria-label")
                    if aria_label:
                        # –ò–∑–≤–ª–µ–∫–∞–µ–º —á–∏—Å–ª–æ –∏–∑ "–û—Ü–µ–Ω–∫–∞ X –ò–∑ 5"
                        rating_match = re.search(
                            r"(?:–û—Ü–µ–Ω–∫–∞|Rating) (\d+) (?:–ò–∑|Out of)",
                            aria_label,
                            re.IGNORECASE,
                        )
                        if rating_match:
                            review_data["rating"] = int(rating_match.group(1))

                # –î–∞—Ç–∞
                date_element = self.navigator.find_element_with_fallback(
                    selectors.REVIEWS["review_date"], element
                )
                if date_element:
                    review_data["date"] = date_element.text.strip()

                # –¢–µ–∫—Å—Ç –æ—Ç–∑—ã–≤–∞
                text_element = self.navigator.find_element_with_fallback(
                    selectors.REVIEWS["review_text"], element
                )
                if text_element:
                    review_data["text"] = text_element.text.strip()

                # –û—Ç–≤–µ—Ç –≤–ª–∞–¥–µ–ª—å—Ü–∞ - –Ω–æ–≤–∞—è –ª–æ–≥–∏–∫–∞
                response_text = self._extract_owner_response(element)
                if response_text:
                    review_data["response"] = response_text

                if review_data.get("author"):
                    reviews.append(review_data)

            except Exception as e:
                self.logger.warning(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—Ç–∑—ã–≤–∞: {e}")
                continue

        self.logger.info(f"–ò–∑–≤–ª–µ—á–µ–Ω–æ {len(reviews)} –æ—Ç–∑—ã–≤–æ–≤")
        return reviews

    def _extract_owner_response(self, review_element) -> Optional[str]:
        """
        –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ –≤–ª–∞–¥–µ–ª—å—Ü–∞ –Ω–∞ –æ—Ç–∑—ã–≤

        Args:
            review_element: –≠–ª–µ–º–µ–Ω—Ç –æ—Ç–∑—ã–≤–∞

        Returns:
            Optional[str]: –¢–µ–∫—Å—Ç –æ—Ç–≤–µ—Ç–∞ –≤–ª–∞–¥–µ–ª—å—Ü–∞ –∏–ª–∏ None
        """
        try:
            # –ò—â–µ–º –∫–Ω–æ–ø–∫—É "–ü–æ—Å–º–æ—Ç—Ä–µ—Ç—å –æ—Ç–≤–µ—Ç –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏"
            response_button = self.navigator.find_element_with_fallback(
                selectors.REVIEWS["review_response_button"], review_element
            )

            if not response_button:
                return None

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –∫–Ω–æ–ø–∫–∞ –¥–ª—è –ø–æ–∫–∞–∑–∞ –æ—Ç–≤–µ—Ç–∞
            button_text = response_button.text.strip().lower()
            if (
                "–ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å –æ—Ç–≤–µ—Ç" not in button_text
                and "–ø–æ–∫–∞–∑–∞—Ç—å –æ—Ç–≤–µ—Ç" not in button_text
            ):
                return None

            # –ö–ª–∏–∫–∞–µ–º –ø–æ –∫–Ω–æ–ø–∫–µ
            if self.navigator.safe_click(response_button):
                # –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –æ—Ç–≤–µ—Ç–∞
                time.sleep(1)

                # –ò—â–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç –æ—Ç–≤–µ—Ç–∞ –≤ —Ç–æ–º –∂–µ review_element –∏–ª–∏ —Ä—è–¥–æ–º —Å –Ω–∏–º
                # –°–Ω–∞—á–∞–ª–∞ –∏—â–µ–º –≤ —Å–∞–º–æ–º —ç–ª–µ–º–µ–Ω—Ç–µ –æ—Ç–∑—ã–≤–∞
                response_content = self.navigator.find_element_with_fallback(
                    selectors.REVIEWS["review_response_content"], review_element
                )

                # –ï—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ —ç–ª–µ–º–µ–Ω—Ç–µ –æ—Ç–∑—ã–≤–∞, –∏—â–µ–º –≤ —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–æ–º –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–µ
                if not response_content:
                    parent_element = review_element.find_element_by_xpath("./..")
                    response_content = self.navigator.find_element_with_fallback(
                        selectors.REVIEWS["review_response_content"], parent_element
                    )

                if response_content:
                    response_text = response_content.text.strip()
                    self.logger.debug(
                        f"–ù–∞–π–¥–µ–Ω –æ—Ç–≤–µ—Ç –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏: {response_text[:50]}..."
                    )
                    return response_text

            return None

        except Exception as e:
            self.logger.debug(f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –æ—Ç–≤–µ—Ç–∞ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏: {e}")
            return None

    def _parse_price(self, price_text: str) -> Dict[str, str]:
        """
        –ü–∞—Ä—Å–∏–Ω–≥ —Ü–µ–Ω—ã –∏–∑ —Ç–µ–∫—Å—Ç–∞

        Args:
            price_text: –¢–µ–∫—Å—Ç —Å —Ü–µ–Ω–æ–π

        Returns:
            Dict: –†–∞—Å–ø–∞—Ä—Å–µ–Ω–Ω–∞—è —Ü–µ–Ω–∞
        """
        result = {}

        if not price_text:
            return result

        # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ —Å–∏–º–≤–æ–ª—ã
        clean_text = re.sub(r"[^\d\s\-‚Äì‚Äî–æ—Ç –¥–æ‚ÇΩ]", "", price_text)

        # –ò—â–µ–º –¥–∏–∞–ø–∞–∑–æ–Ω —Ü–µ–Ω (–Ω–∞–ø—Ä–∏–º–µ—Ä, "2000-3000" –∏–ª–∏ "–æ—Ç 2000 –¥–æ 3000")
        range_match = re.search(r"(\d+)\s*[-‚Äì‚Äî]\s*(\d+)", clean_text)
        if range_match:
            result["price_from"] = range_match.group(1)
            result["price_to"] = range_match.group(2)
            result["price"] = f"{result['price_from']}-{result['price_to']}"
            return result

        # –ò—â–µ–º "–æ—Ç X" –∏–ª–∏ "–¥–æ X"
        from_match = re.search(r"–æ—Ç\s*(\d+)", clean_text)
        to_match = re.search(r"–¥–æ\s*(\d+)", clean_text)

        if from_match:
            result["price_from"] = from_match.group(1)
            result["price"] = f"–æ—Ç {result['price_from']}"
        elif to_match:
            result["price_to"] = to_match.group(1)
            result["price"] = f"–¥–æ {result['price_to']}"
        else:
            # –ò—â–µ–º –ø—Ä–æ—Å—Ç–æ–µ —á–∏—Å–ª–æ
            simple_match = re.search(r"(\d+)", clean_text)
            if simple_match:
                result["price"] = simple_match.group(1)

        return result

    def scrape_business(
        self, url: str, max_reviews: int = 50
    ) -> Optional[BusinessData]:
        """
        –ü–æ–ª–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –æ –ø—Ä–µ–¥–ø—Ä–∏—è—Ç–∏–∏

        Args:
            url: URL —Å—Ç—Ä–∞–Ω–∏—Ü—ã –ø—Ä–µ–¥–ø—Ä–∏—è—Ç–∏—è

        Returns:
            BusinessData: –ò–∑–≤–ª–µ—á–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–ª–∏ None
        """
        if not self.driver:
            raise RuntimeError("WebDriver –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")

        self.logger.info(f"–ù–∞—á–∏–Ω–∞–µ–º —Å–∫—Ä–∞–ø–∏–Ω–≥: {url}")

        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É
            if not self.load_page(url):
                return None

            # –ü–∞—É–∑–∞ –ø–æ—Å–ª–µ –∑–∞–≥—Ä—É–∑–∫–∏
            self.navigator.random_delay()

            # –ò–∑–≤–ª–µ–∫–∞–µ–º –±–∞–∑–æ–≤—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
            basic_data = self.extract_basic_info()

            if not basic_data.get("name"):
                self.logger.error("–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –Ω–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–µ–¥–ø—Ä–∏—è—Ç–∏—è")
                return None

            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å–æ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–µ—Ç–∏
            social_data = self.extract_social_networks()

            # –î–∞–Ω–Ω—ã–µ —É—Å–ª—É–≥
            services_data = []
            if self.navigate_to_services_tab():
                self.navigator.random_delay()
                services_data = self.extract_services()

            # –î–∞–Ω–Ω—ã–µ –æ—Ç–∑—ã–≤–æ–≤
            reviews_data = []
            if self.navigate_to_reviews_tab():
                self.navigator.random_delay()
                reviews_data = self.extract_reviews(max_reviews=max_reviews)

            # –°–æ–∑–¥–∞–µ–º –æ–±—ä–µ–∫—Ç –¥–∞–Ω–Ω—ã—Ö
            business_data = BusinessData(
                name=basic_data.get("name", ""),
                category=basic_data.get("category"),
                services=[ServiceData(**service) for service in services_data],
                website=basic_data.get("website"),
                address=basic_data.get("address"),
                social_networks=SocialNetworks(**social_data),
                phone=basic_data.get("phone"),
                working_hours=WorkingHours(**basic_data.get("working_hours", {})),
                rating=basic_data.get("rating"),
                reviews_count=basic_data.get("reviews_count"),
                reviews=[ReviewData(**review) for review in reviews_data],
                metadata={
                    "source_url": url,
                    "scraper_version": "1.0",
                    "processing_time_sec": (
                        round(time.time() - self.start_time, 2)
                        if self.start_time
                        else 0
                    ),
                },
            )

            # –õ–æ–≥–∏—Ä—É–µ–º —É—Å–ø–µ—à–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            processing_time = time.time() - self.start_time if self.start_time else 0
            data_extracted = (
                len(services_data)
                + len(reviews_data)
                + len([k for k, v in basic_data.items() if v])
            )

            log_scraping_stats(url, True, processing_time, data_extracted)
            scraping_metrics.record_request(True, processing_time)

            self.logger.info(f"–°–∫—Ä–∞–ø–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ –∑–∞ {processing_time:.2f}s")
            return business_data

        except Exception as e:
            processing_time = time.time() - self.start_time if self.start_time else 0
            error_msg = str(e)

            log_scraping_stats(url, False, processing_time, 0, error_msg)
            scraping_metrics.record_request(False, processing_time, error_msg)

            self.logger.error(f"–û—à–∏–±–∫–∞ —Å–∫—Ä–∞–ø–∏–Ω–≥–∞: {e}")
            return None
