"""
–ü–∞—Ä—Å–µ—Ä –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –æ—Ç–∑—ã–≤–æ–≤
"""

import re
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple

from .base_parser import BaseParser, ParseResult, TextNormalizer


class ReviewParser(BaseParser):
    """–ü–∞—Ä—Å–µ—Ä –¥–ª—è –æ—Ç–∑—ã–≤–æ–≤ –æ –ø—Ä–µ–¥–ø—Ä–∏—è—Ç–∏—è—Ö"""

    # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ —Ä–µ–π—Ç–∏–Ω–≥–∞
    RATING_PATTERNS = [
        r"(\d)\s*(?:–∏–∑\s*5|/5|\*|‚òÖ)",  # X –∏–∑ 5, X/5, X*, X‚òÖ
        r"(\d+)\s*–∑–≤–µ–∑–¥[—ã–∞]?",  # X –∑–≤–µ–∑–¥
        r"(\d+)\s*–±–∞–ª–ª[–∞–æ]–≤?",  # X –±–∞–ª–ª–æ–≤
        r"–æ—Ü–µ–Ω–∫–∞:\s*(\d+)",  # –û—Ü–µ–Ω–∫–∞: X
    ]

    # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –¥–∞—Ç
    DATE_PATTERNS = [
        # –ü–æ–ª–Ω—ã–µ –¥–∞—Ç—ã —Å –≥–æ–¥–æ–º
        (
            r"(\d{1,2})\s+(—è–Ω–≤–∞—Ä—è|—Ñ–µ–≤—Ä–∞–ª—è|–º–∞—Ä—Ç–∞|–∞–ø—Ä–µ–ª—è|–º–∞—è|–∏—é–Ω—è|–∏—é–ª—è|–∞–≤–≥—É—Å—Ç–∞|—Å–µ–Ω—Ç—è–±—Ä—è|–æ–∫—Ç—è–±—Ä—è|–Ω–æ—è–±—Ä—è|–¥–µ–∫–∞–±—Ä—è)\s+(\d{4})",
            "ru_full",
        ),
        (
            r"(\d{1,2})\s+(Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)\s+(\d{4})",
            "en_full",
        ),
        # –î–∞—Ç—ã –±–µ–∑ –≥–æ–¥–∞
        (
            r"(\d{1,2})\s+(—è–Ω–≤–∞—Ä—è|—Ñ–µ–≤—Ä–∞–ª—è|–º–∞—Ä—Ç–∞|–∞–ø—Ä–µ–ª—è|–º–∞—è|–∏—é–Ω—è|–∏—é–ª—è|–∞–≤–≥—É—Å—Ç–∞|—Å–µ–Ω—Ç—è–±—Ä—è|–æ–∫—Ç—è–±—Ä—è|–Ω–æ—è–±—Ä—è|–¥–µ–∫–∞–±—Ä—è)",
            "ru_short",
        ),
        (r"(\d{1,2})\s+(Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)", "en_short"),
        # –ß–∏—Å–ª–æ–≤—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã
        (r"(\d{1,2})\.(\d{1,2})\.(\d{2,4})", "numeric_dot"),
        (r"(\d{1,2})/(\d{1,2})/(\d{2,4})", "numeric_slash"),
        (r"(\d{4})-(\d{1,2})-(\d{1,2})", "iso"),
        # –û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–µ –¥–∞—Ç—ã
        (r"(—Å–µ–≥–æ–¥–Ω—è|–≤—á–µ—Ä–∞|–ø–æ–∑–∞–≤—á–µ—Ä–∞)", "relative_ru"),
        (r"(today|yesterday)", "relative_en"),
        (r"(\d+)\s*(?:–¥–Ω|–¥–Ω—è|–¥–Ω–µ–π|day|days)\s*–Ω–∞–∑–∞–¥", "days_ago"),
        (r"(\d+)\s*(?:–Ω–µ–¥|–Ω–µ–¥–µ–ª[–∏—å]|week|weeks)\s*–Ω–∞–∑–∞–¥", "weeks_ago"),
        (r"(\d+)\s*(?:–º–µ—Å|–º–µ—Å—è—Ü[–∞–µ]–≤?|month|months)\s*–Ω–∞–∑–∞–¥", "months_ago"),
    ]

    # –ò–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –æ—Ç–≤–µ—Ç–∞ –≤–ª–∞–¥–µ–ª—å—Ü–∞
    OWNER_RESPONSE_INDICATORS = [
        "–æ—Ç–≤–µ—Ç –≤–ª–∞–¥–µ–ª—å—Ü–∞",
        "–æ—Ç–≤–µ—Ç –∑–∞–≤–µ–¥–µ–Ω–∏—è",
        "–æ—Ç –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ü–∏–∏",
        "owner response",
        "business response",
        "management response",
        "–∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä",
        "–º–µ–Ω–µ–¥–∂–µ—Ä",
        "—Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ",
    ]

    # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∏–º–µ–Ω –∞–≤—Ç–æ—Ä–æ–≤
    AUTHOR_PATTERNS = [
        r"^([–ê-–Ø][–∞-—è]+\s+[–ê-–Ø]\.?)$",  # –ò–º—è –§.
        r"^([–ê-–Ø][–∞-—è]+)$",  # –ü—Ä–æ—Å—Ç–æ –∏–º—è
        r"^([A-Z][a-z]+\s+[A-Z]\.?)$",  # English Name F.
        r"^([A-Z][a-z]+)$",  # English name
    ]

    def parse(self, raw_data: str) -> ParseResult:
        """
        –û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –ø–∞—Ä—Å–∏–Ω–≥–∞ –æ—Ç–∑—ã–≤–æ–≤

        Args:
            raw_data: –°—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ –æ—Ç–∑—ã–≤–æ–≤

        Returns:
            ParseResult: –†–µ–∑—É–ª—å—Ç–∞—Ç –ø–∞—Ä—Å–∏–Ω–≥–∞
        """
        if not raw_data:
            return self.create_result([], success=False, confidence=0.0)

        try:
            # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ –æ—Ç–¥–µ–ª—å–Ω—ã–µ –æ—Ç–∑—ã–≤—ã
            review_blocks = self._split_reviews(raw_data)

            # –ü–∞—Ä—Å–∏–º –∫–∞–∂–¥—ã–π –æ—Ç–∑—ã–≤
            parsed_reviews = []
            total_confidence = 0.0

            for block in review_blocks:
                review_data = self._parse_single_review(block)
                if review_data:
                    parsed_reviews.append(review_data["data"])
                    total_confidence += review_data["confidence"]

            # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ä–µ–¥–Ω—é—é —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
            avg_confidence = (
                total_confidence / len(review_blocks) if review_blocks else 0.0
            )

            return self.create_result(
                data=parsed_reviews,
                success=len(parsed_reviews) > 0,
                confidence=avg_confidence,
            )

        except Exception as e:
            result = self.create_result([], success=False, confidence=0.0)
            result.add_error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –æ—Ç–∑—ã–≤–æ–≤: {str(e)}")
            return result

    def _split_reviews(self, text: str) -> List[str]:
        """–†–∞–∑–¥–µ–ª–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ –æ—Ç–¥–µ–ª—å–Ω—ã–µ –æ—Ç–∑—ã–≤—ã"""

        # –†–∞–∑–ª–∏—á–Ω—ã–µ —Å–ø–æ—Å–æ–±—ã —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –æ—Ç–∑—ã–≤–æ–≤
        separators = [
            r"\n\s*[-‚Ä¢*]\s*",  # –ú–∞—Ä–∫–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–ø–∏—Å–∫–∏
            r"\n\s*\d+\.\s*",  # –ù—É–º–µ—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–ø–∏—Å–∫–∏
            r"\n{3,}",  # –ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø–µ—Ä–µ–Ω–æ—Å—ã
            r"(?=\n[–ê-–Ø][–∞-—è]+\s+[–ê-–Ø]\.)",  # –ù–æ–≤—ã–π –æ—Ç–∑—ã–≤ —Å –∏–º–µ–Ω–µ–º –∞–≤—Ç–æ—Ä–∞
            r"(?=\n\d+\s+(?:–∑–≤–µ–∑–¥|‚òÖ))",  # –ù–æ–≤—ã–π –æ—Ç–∑—ã–≤ —Å —Ä–µ–π—Ç–∏–Ω–≥–æ–º
        ]

        # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏ –ø–æ –ø–æ—Ä—è–¥–∫—É
        for separator in separators:
            blocks = re.split(separator, text)
            if len(blocks) > 1:
                cleaned_blocks = []
                for block in blocks:
                    cleaned = self.clean_text(block)
                    if len(cleaned) > 20:  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –æ—Ç–∑—ã–≤–∞
                        cleaned_blocks.append(cleaned)

                if len(cleaned_blocks) > 1:
                    return cleaned_blocks

        # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å —Ä–∞–∑–¥–µ–ª–∏—Ç—å, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç
        return [text] if text.strip() else []

    def _parse_single_review(self, review_text: str) -> Optional[Dict]:
        """–ü–∞—Ä—Å–∏–Ω–≥ –æ–¥–Ω–æ–≥–æ –æ—Ç–∑—ã–≤–∞"""

        if not review_text or len(review_text.strip()) < 10:
            return None

        review_data = {
            "author": "",
            "rating": None,
            "date": None,
            "text": None,
            "response": None,
            "helpful_count": None,
        }

        confidence = 0.3  # –ë–∞–∑–æ–≤–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å

        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∞–≤—Ç–æ—Ä–∞
        author_info = self._extract_author(review_text)
        if author_info:
            review_data["author"] = author_info["name"]
            confidence += 0.2

        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ä–µ–π—Ç–∏–Ω–≥
        rating_info = self._extract_rating(review_text)
        if rating_info:
            review_data["rating"] = rating_info
            confidence += 0.2

        # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞—Ç—É
        date_info = self.parse_date(review_text)
        if date_info:
            review_data["date"] = date_info
            confidence += 0.1

        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –æ—Ç–∑—ã–≤–∞ –∏ –æ—Ç–≤–µ—Ç
        text_info = self._extract_review_text(review_text)
        if text_info:
            review_data["text"] = text_info.get("review_text")
            review_data["response"] = text_info.get("owner_response")
            confidence += 0.2

        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ "–ø–æ–ª–µ–∑–Ω–æ"
        helpful_info = self._extract_helpful_count(review_text)
        if helpful_info:
            review_data["helpful_count"] = helpful_info
            confidence += 0.1

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è
        if not review_data["author"]:
            return None

        return {"data": review_data, "confidence": min(confidence, 1.0)}

    def _extract_author(self, text: str) -> Optional[Dict]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∞–≤—Ç–æ—Ä–∞ –æ—Ç–∑—ã–≤–∞"""

        # –ò—â–µ–º –≤ –Ω–∞—á–∞–ª–µ —Ç–µ–∫—Å—Ç–∞
        lines = text.split("\n")
        for line in lines[:3]:  # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–≤—ã–µ 3 —Å—Ç—Ä–æ–∫–∏
            line = line.strip()

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã –∏–º–µ–Ω
            for pattern in self.AUTHOR_PATTERNS:
                match = re.match(pattern, line)
                if match:
                    name = match.group(1).strip()
                    if 2 <= len(name) <= 50:  # –†–∞–∑—É–º–Ω–∞—è –¥–ª–∏–Ω–∞ –∏–º–µ–Ω–∏
                        return {"name": name}

        # –ï—Å–ª–∏ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–∏, –∏—â–µ–º –ø–µ—Ä–≤–æ–µ "—Ä–∞–∑—É–º–Ω–æ–µ" —Å–ª–æ–≤–æ
        words = text.split()
        for word in words[:5]:  # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–≤—ã–µ 5 —Å–ª–æ–≤
            cleaned_word = re.sub(r"[^\w\s.-]", "", word, flags=re.UNICODE)
            if (
                len(cleaned_word) >= 2
                and cleaned_word[0].isupper()
                and not cleaned_word.isdigit()
            ):
                return {"name": cleaned_word}

        return None

    def _extract_rating(self, text: str) -> Optional[int]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ä–µ–π—Ç–∏–Ω–≥–∞"""

        for pattern in self.RATING_PATTERNS:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                try:
                    rating = int(match.group(1))
                    if 1 <= rating <= 5:
                        return rating
                except (ValueError, IndexError):
                    continue

        # –ò—â–µ–º –∑–≤–µ–∑–¥–æ—á–∫–∏
        stars_match = re.search(r"(‚òÖ+)", text)
        if stars_match:
            star_count = len(stars_match.group(1))
            if 1 <= star_count <= 5:
                return star_count

        return None

    def parse_date(self, date_text: str) -> Optional[str]:
        """
        –ü–∞—Ä—Å–∏–Ω–≥ –¥–∞—Ç—ã –æ—Ç–∑—ã–≤–∞

        Args:
            date_text: –¢–µ–∫—Å—Ç —Å –¥–∞—Ç–æ–π

        Returns:
            Optional[str]: –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–∞—è –¥–∞—Ç–∞
        """
        if not date_text:
            return None

        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—ã–π –ø–∞—Ç—Ç–µ—Ä–Ω
        for pattern, format_type in self.DATE_PATTERNS:
            match = re.search(pattern, date_text, re.IGNORECASE)
            if match:
                try:
                    if format_type in ["ru_full", "en_full"]:
                        day, month, year = match.groups()
                        month_num = TextNormalizer.normalize_month_name(month)
                        if month_num:
                            return f"{day} {month} {year}"

                    elif format_type in ["ru_short", "en_short"]:
                        day, month = match.groups()
                        month_num = TextNormalizer.normalize_month_name(month)
                        current_year = datetime.now().year
                        if month_num:
                            return f"{day} {month} {current_year}"

                    elif format_type == "numeric_dot":
                        day, month, year = match.groups()
                        if len(year) == 2:
                            year = f"20{year}" if int(year) <= 30 else f"19{year}"
                        return f"{day}.{month}.{year}"

                    elif format_type == "numeric_slash":
                        month, day, year = match.groups()  # –ê–º–µ—Ä–∏–∫–∞–Ω—Å–∫–∏–π —Ñ–æ—Ä–º–∞—Ç
                        if len(year) == 2:
                            year = f"20{year}" if int(year) <= 30 else f"19{year}"
                        return f"{day}.{month}.{year}"

                    elif format_type == "iso":
                        year, month, day = match.groups()
                        return f"{day}.{month}.{year}"

                    elif format_type == "relative_ru":
                        relative = match.group(1).lower()
                        if relative == "—Å–µ–≥–æ–¥–Ω—è":
                            return datetime.now().strftime("%d.%m.%Y")
                        elif relative == "–≤—á–µ—Ä–∞":
                            return (datetime.now() - timedelta(days=1)).strftime(
                                "%d.%m.%Y"
                            )
                        elif relative == "–ø–æ–∑–∞–≤—á–µ—Ä–∞":
                            return (datetime.now() - timedelta(days=2)).strftime(
                                "%d.%m.%Y"
                            )

                    elif format_type == "relative_en":
                        relative = match.group(1).lower()
                        if relative == "today":
                            return datetime.now().strftime("%d.%m.%Y")
                        elif relative == "yesterday":
                            return (datetime.now() - timedelta(days=1)).strftime(
                                "%d.%m.%Y"
                            )

                    elif format_type == "days_ago":
                        days = int(match.group(1))
                        if days <= 365:  # –ú–∞–∫—Å–∏–º—É–º –≥–æ–¥ –Ω–∞–∑–∞–¥
                            return (datetime.now() - timedelta(days=days)).strftime(
                                "%d.%m.%Y"
                            )

                    elif format_type == "weeks_ago":
                        weeks = int(match.group(1))
                        if weeks <= 52:  # –ú–∞–∫—Å–∏–º—É–º –≥–æ–¥ –Ω–∞–∑–∞–¥
                            return (datetime.now() - timedelta(weeks=weeks)).strftime(
                                "%d.%m.%Y"
                            )

                    elif format_type == "months_ago":
                        months = int(match.group(1))
                        if months <= 12:  # –ú–∞–∫—Å–∏–º—É–º –≥–æ–¥ –Ω–∞–∑–∞–¥
                            return (
                                datetime.now() - timedelta(days=months * 30)
                            ).strftime("%d.%m.%Y")

                except (ValueError, TypeError):
                    continue

        return None

    def _extract_review_text(self, text: str) -> Optional[Dict]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –æ—Ç–∑—ã–≤–∞ –∏ –æ—Ç–≤–µ—Ç–∞ –≤–ª–∞–¥–µ–ª—å—Ü–∞"""

        # –£–±–∏—Ä–∞–µ–º –º–µ—Ç–∞–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é (–∞–≤—Ç–æ—Ä, –¥–∞—Ç–∞, —Ä–µ–π—Ç–∏–Ω–≥)
        cleaned_text = text

        # –£–±–∏—Ä–∞–µ–º —Å—Ç—Ä–æ–∫–∏ —Å –∞–≤—Ç–æ—Ä–æ–º
        lines = cleaned_text.split("\n")
        filtered_lines = []

        for line in lines:
            line_stripped = line.strip()

            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å—Ç—Ä–æ–∫–∏ —Å –∏–º–µ–Ω–∞–º–∏ –∞–≤—Ç–æ—Ä–æ–≤
            if any(
                re.match(pattern, line_stripped) for pattern in self.AUTHOR_PATTERNS
            ):
                continue

            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å—Ç—Ä–æ–∫–∏ —Å —Ä–µ–π—Ç–∏–Ω–≥–∞–º–∏
            if any(
                re.search(pattern, line_stripped, re.IGNORECASE)
                for pattern in self.RATING_PATTERNS
            ):
                continue

            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å—Ç—Ä–æ–∫–∏ —Å –¥–∞—Ç–∞–º–∏
            if any(
                re.search(pattern[0], line_stripped, re.IGNORECASE)
                for pattern in self.DATE_PATTERNS
            ):
                continue

            # –î–æ–±–∞–≤–ª—è–µ–º –æ—Å—Ç–∞–≤—à–∏–µ—Å—è —Å—Ç—Ä–æ–∫–∏
            if len(line_stripped) > 5:
                filtered_lines.append(line_stripped)

        if not filtered_lines:
            return None

        full_text = " ".join(filtered_lines)

        # –ò—â–µ–º –æ—Ç–≤–µ—Ç –≤–ª–∞–¥–µ–ª—å—Ü–∞
        owner_response = None
        review_text = full_text

        for indicator in self.OWNER_RESPONSE_INDICATORS:
            if indicator in full_text.lower():
                parts = re.split(indicator, full_text, 1, re.IGNORECASE)
                if len(parts) == 2:
                    review_text = parts[0].strip()
                    owner_response = parts[1].strip()
                    break

        # –û—á–∏—â–∞–µ–º —Ç–µ–∫—Å—Ç—ã
        if review_text:
            review_text = self.clean_text(review_text)

        if owner_response:
            owner_response = self.clean_text(owner_response)

        return {
            "review_text": review_text if len(review_text) > 10 else None,
            "owner_response": (
                owner_response if owner_response and len(owner_response) > 10 else None
            ),
        }

    def _extract_helpful_count(self, text: str) -> Optional[int]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –æ—Ç–º–µ—Ç–æ–∫ '–ø–æ–ª–µ–∑–Ω–æ'"""

        helpful_patterns = [
            r"(\d+)\s*(?:–ø–æ–ª–µ–∑–Ω|helpful|like)",
            r"(?:–ø–æ–ª–µ–∑–Ω|helpful|like).*?(\d+)",
            r"üëç\s*(\d+)",
            r"(\d+)\s*üëç",
        ]

        for pattern in helpful_patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                try:
                    count = int(match.group(1))
                    if 0 <= count <= 10000:  # –†–∞–∑—É–º–Ω—ã–π –¥–∏–∞–ø–∞–∑–æ–Ω
                        return count
                except (ValueError, IndexError):
                    continue

        return None

    def analyze_sentiment(self, review_text: str) -> Dict[str, any]:
        """–ë–∞–∑–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ –æ—Ç–∑—ã–≤–∞"""

        if not review_text:
            return {"sentiment": "neutral", "confidence": 0.0}

        text_lower = review_text.lower()

        # –ü–æ–∑–∏—Ç–∏–≤–Ω—ã–µ —Å–ª–æ–≤–∞
        positive_words = [
            "–æ—Ç–ª–∏—á–Ω–æ",
            "–ø—Ä–µ–∫—Ä–∞—Å–Ω–æ",
            "–∑–∞–º–µ—á–∞—Ç–µ–ª—å–Ω–æ",
            "–≤–µ–ª–∏–∫–æ–ª–µ–ø–Ω–æ",
            "—Å—É–ø–µ—Ä",
            "–∫–ª–∞—Å—Å",
            "–∫—Ä—É—Ç–æ",
            "–≤–æ—Å—Ö–∏—Ç–∏—Ç–µ–ª—å–Ω–æ",
            "–ø—Ä–µ–≤–æ—Å—Ö–æ–¥–Ω–æ",
            "—à–∏–∫–∞—Ä–Ω–æ",
            "—Ä–µ–∫–æ–º–µ–Ω–¥—É—é",
            "—Å–æ–≤–µ—Ç—É—é",
            "–¥–æ–≤–æ–ª—å–Ω",
            "–ø–æ–Ω—Ä–∞–≤–∏–ª",
            "—Ö–æ—Ä–æ—à–æ",
        ]

        # –ù–µ–≥–∞—Ç–∏–≤–Ω—ã–µ —Å–ª–æ–≤–∞
        negative_words = [
            "–ø–ª–æ—Ö–æ",
            "—É–∂–∞—Å–Ω–æ",
            "–∫–æ—à–º–∞—Ä",
            "–æ—Ç–≤—Ä–∞—Ç–∏—Ç–µ–ª—å–Ω–æ",
            "–º–µ—Ä–∑–∫–æ",
            "–Ω–µ —Ä–µ–∫–æ–º–µ–Ω–¥—É—é",
            "—Ä–∞–∑–æ—á–∞—Ä–æ–≤–∞–Ω",
            "—Ä–∞—Å—Å—Ç—Ä–æ–µ–Ω",
            "–Ω–µ–¥–æ–≤–æ–ª–µ–Ω",
            "–∂–∞–ª—å",
            "—Å–æ–∂–∞–ª–µ—é",
            "–ø—Ä–æ–±–ª–µ–º",
            "–æ—à–∏–±–∫",
            "–Ω–µ—É–¥–∞—á",
        ]

        positive_count = sum(1 for word in positive_words if word in text_lower)
        negative_count = sum(1 for word in negative_words if word in text_lower)

        if positive_count > negative_count:
            sentiment = "positive"
            confidence = min(
                positive_count / (positive_count + negative_count + 1), 0.9
            )
        elif negative_count > positive_count:
            sentiment = "negative"
            confidence = min(
                negative_count / (positive_count + negative_count + 1), 0.9
            )
        else:
            sentiment = "neutral"
            confidence = 0.5

        return {
            "sentiment": sentiment,
            "confidence": confidence,
            "positive_indicators": positive_count,
            "negative_indicators": negative_count,
        }

    def extract_review_topics(self, review_text: str) -> List[str]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–º/–∞—Å–ø–µ–∫—Ç–æ–≤ –∏–∑ –æ—Ç–∑—ã–≤–∞"""

        if not review_text:
            return []

        # –°–ª–æ–≤–∞—Ä—å —Ç–µ–º –∏ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
        topics = {
            "service": [
                "—Å–µ—Ä–≤–∏—Å",
                "–æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏–µ",
                "–ø–µ—Ä—Å–æ–Ω–∞–ª",
                "—Å–æ—Ç—Ä—É–¥–Ω–∏–∫",
                "–∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä",
            ],
            "quality": ["–∫–∞—á–µ—Å—Ç–≤–æ", "—Ä–µ–∑—É–ª—å—Ç–∞—Ç", "—Ä–∞–±–æ—Ç–∞", "–≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ"],
            "price": ["—Ü–µ–Ω–∞", "—Å—Ç–æ–∏–º–æ—Å—Ç—å", "–¥–æ—Ä–æ–≥–æ", "–¥–µ—à–µ–≤–æ", "–¥–µ–Ω—å–≥–∏"],
            "atmosphere": ["–∞—Ç–º–æ—Å—Ñ–µ—Ä–∞", "–∏–Ω—Ç–µ—Ä—å–µ—Ä", "–æ–±—Å—Ç–∞–Ω–æ–≤–∫–∞", "—É—é—Ç"],
            "cleanliness": ["—á–∏—Å—Ç–æ—Ç–∞", "—á–∏—Å—Ç–æ", "–≥—Ä—è–∑–Ω–æ", "—É–±—Ä–∞–Ω–æ"],
            "time": ["–≤—Ä–µ–º—è", "–±—ã—Å—Ç—Ä–æ", "–¥–æ–ª–≥–æ", "–æ–ø–æ–∑–¥–∞–Ω–∏–µ", "–æ–∂–∏–¥–∞–Ω–∏–µ"],
            "location": ["–º–µ—Å—Ç–æ", "—Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω–∏–µ", "–ø–∞—Ä–∫–æ–≤–∫–∞", "–¥–æ–±—Ä–∞—Ç—å—Å—è"],
        }

        text_lower = review_text.lower()
        found_topics = []

        for topic, keywords in topics.items():
            if any(keyword in text_lower for keyword in keywords):
                found_topics.append(topic)

        return found_topics[:3]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–µ–º
